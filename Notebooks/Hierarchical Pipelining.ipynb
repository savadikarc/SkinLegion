{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports.\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Keras imports.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "\n",
    "# Custom imports.\n",
    "from configuration import HierarchicalConfig\n",
    "\n",
    "c = HierarchicalConfig()\n",
    "conf = c.config_dict\n",
    "\n",
    "if not os.path.exists(conf['CACHE_DIR']):\n",
    "    os.makedirs(conf['CACHE_DIR'])\n",
    "    \n",
    "num_images = len(os.listdir(conf['TEST_IMG_DIR'] + 'test'))\n",
    "print(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nv_non_nv(im):\n",
    "    return im - conf['MODEL_MEANS']['NV_NON_NV']\n",
    "\n",
    "def preprocess_df_vasc(im):\n",
    "    return im - conf['MODEL_MEANS']['DF_VASC_OTHERS']\n",
    "\n",
    "def preprocess_bkl_mel_others(im):\n",
    "    return im - conf['MODEL_MEANS']['MEL_BKL']\n",
    "\n",
    "def preprocess_akiec_others(im):\n",
    "    return im - conf['MODEL_MEANS']['AKIEC_OTHERS']\n",
    "\n",
    "def preprocess_bcc_others(im):\n",
    "    return im - conf['MODEL_MEANS']['BCC_OTHERS']\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return ( 2*(precision * recall) / (precision + recall + K.epsilon()) )\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return (true_positives / (possible_positives + K.epsilon()))\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return (true_positives / (predicted_positives + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(tag, verbose=0):\n",
    "    \n",
    "    prediction_dict = dict()\n",
    "    \n",
    "    custom_obj = {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "    \n",
    "    if tag == 'NV_NON_NV':\n",
    "        gen = ImageDataGenerator(preprocessing_function=preprocess_nv_non_nv, rescale=1./255)\n",
    "    elif tag == 'DF_VASC_OTHERS':\n",
    "        gen = ImageDataGenerator(preprocessing_function=preprocess_df_vasc, rescale=1./255)\n",
    "    elif tag == 'MEL_BKL':\n",
    "        gen = ImageDataGenerator(preprocessing_function=preprocess_bkl_mel_others, rescale=1./255)\n",
    "    elif tag == 'AKIEC_OTHERS':\n",
    "        gen = ImageDataGenerator(preprocessing_function=preprocess_akiec_others, rescale=1./255)\n",
    "    else:\n",
    "        # Intentionally not adding another else-if.\n",
    "        gen = ImageDataGenerator(preprocessing_function=preprocess_bcc_others, rescale=1./255)\n",
    "    \n",
    "    if tag in conf['MODEL_NAMES'].keys():\n",
    "        print('Loading {}'.format(tag))\n",
    "    else:\n",
    "        raise AttributeError('{} not in model name repo'.format(tag))\n",
    "    \n",
    "    best_model = load_model(conf['MODEL_NAMES'][tag], compile=True, custom_objects=custom_obj)\n",
    "    print('{} Model loaded.'.format(tag))\n",
    "    \n",
    "    if tag == 'NV_NON_NV':\n",
    "        images = gen.flow_from_directory(conf['TEST_IMG_DIR'], \n",
    "                                         target_size=conf['NV_IMG_DIMS'], \n",
    "                                         shuffle=False, \n",
    "                                         batch_size=conf['BATCH_SIZE'], \n",
    "                                         class_mode=None)\n",
    "    else:\n",
    "        images = gen.flow_from_directory(conf['TEST_IMG_DIR'], \n",
    "                                         target_size=conf['OTHER_IMG_DIMS'], \n",
    "                                         shuffle=False,\n",
    "                                         batch_size=conf['BATCH_SIZE'], \n",
    "                                         class_mode=None)\n",
    "    \n",
    "    predictions = best_model.predict_generator(images, verbose=verbose)\n",
    "    filenames = images.filenames\n",
    "    \n",
    "    if len(conf['MODEL_TAGS'][tag]) == 2:\n",
    "        # Binary.\n",
    "        positive_preds = predictions[predictions >= 0.5]\n",
    "        negative_preds = predictions[predictions < 0.5]\n",
    "        \n",
    "        assert len(positive_preds) + len(negative_preds) == images.samples, \"Length mismatch for {}\".format(tag)\n",
    "        \n",
    "        if verbose > 0:\n",
    "            print('Predicted {} positive examples.'.format(len(positive_preds)))\n",
    "            print('Predicted {} negative examples.'.format(len(negative_preds)))\n",
    "        \n",
    "        if tag == 'MEL_BKL':\n",
    "            positive_indices = np.where(predictions >= 0.5)[0]\n",
    "            negative_indices = np.where(predictions < 0.5)[0]\n",
    "\n",
    "            positive_images = [filenames[p] for p in positive_indices]\n",
    "            negative_images = [filenames[n] for n in negative_indices]\n",
    "            \n",
    "            preds_pos = dict()\n",
    "            for image, ix in zip(positive_images, positive_indices):\n",
    "                stripped_im = image[image.index('/')+1:].strip('.jpg')\n",
    "                preds_pos[stripped_im] = predictions[ix][0]\n",
    "            prediction_dict[conf['MODEL_TAGS'][tag][-1]] = preds_pos\n",
    "                \n",
    "            preds_neg = dict()\n",
    "            for image, ix in zip(negative_images, negative_indices):\n",
    "                stripped_im = image[image.index('/')+1:].strip('.jpg')\n",
    "                preds_neg[stripped_im] = 1 - predictions[ix][0]\n",
    "            prediction_dict[conf['MODEL_TAGS'][tag][0]] = preds_neg\n",
    "        else:\n",
    "            positive_indices = np.where(predictions >= 0.5)[0]\n",
    "            negative_indices = np.where(predictions < 0.5)[0]\n",
    "\n",
    "            positive_images = [filenames[p] for p in positive_indices]\n",
    "            negative_images = [filenames[n] for n in negative_indices]\n",
    "        \n",
    "            assert len(positive_indices) == len(positive_images)\n",
    "\n",
    "            # An image name -> Prediction mapping.\n",
    "            preds = dict()\n",
    "            for image, ix in zip(positive_images, positive_indices):\n",
    "                stripped_im = image[image.index('/')+1:].strip('.jpg')\n",
    "                preds[stripped_im] = predictions[ix][0]\n",
    "\n",
    "            # Class -> (image names -> predictions).\n",
    "            prediction_dict[conf['MODEL_TAGS'][tag][-1]] = preds\n",
    "\n",
    "            # Now, we move all the positive predictions out.\n",
    "            for im in positive_images:\n",
    "                try:\n",
    "                    stripped_im = im[im.index('/')+1:]\n",
    "                    shutil.move(src=conf['TEST_IMG_DIR']+im, \n",
    "                                dst=conf['CACHE_DIR']+'/'+stripped_im)\n",
    "                except IOError:\n",
    "                    print('Error while moving file {}'.format(im))\n",
    "            if verbose > 0:\n",
    "                print('Moved {} positive images to cache directory.'.format(len(positive_images)))\n",
    "        \n",
    "    \n",
    "    elif len(conf['MODEL_TAGS'][tag]) > 2:\n",
    "        # Multi-class. Predictions will be (m*n).\n",
    "        num_classes = predictions.shape[1]\n",
    "        classes = conf['MODEL_TAGS'][tag]\n",
    "        \n",
    "        assert len(classes) == num_classes, \"Mismatch in feature dimension for {}.\".format(tag)\n",
    "        assert len(filenames) == predictions.shape[0], \"Mismatch in image dimension for {}\".format(tag)\n",
    "        \n",
    "        # Split the prediction matrix into {classes}:others\n",
    "        preds_for_others = predictions[:, -1]\n",
    "        class_preds = predictions[:, :-1]\n",
    "        \n",
    "        # These are the indices for files which are predicted as 'others'.\n",
    "        others_predictions = np.where(preds_for_others > 0.5)[0]\n",
    "        others_filenames = [filenames[o] for o in others_predictions]\n",
    "        print('Identified {} images as \\'others\\''.format(len(others_filenames)))\n",
    "        \n",
    "        for class_name in classes[:-1]:\n",
    "            prediction_dict[class_name] = dict()\n",
    "        \n",
    "        images_to_move = set()\n",
    "        for col_ix in range(class_preds.shape[1]):\n",
    "            _dict = dict()\n",
    "            for row_ix in range(class_preds.shape[0]):\n",
    "                if filenames[row_ix] not in others_filenames:\n",
    "                    filename = filenames[row_ix]\n",
    "                    images_to_move.add(filename)\n",
    "                    stripped_name = filename[filename.index('/')+1:].strip('.jpg')\n",
    "                    _dict[filenames[row_ix]] = class_preds[row_ix, col_ix]\n",
    "                    \n",
    "            prediction_dict[classes[col_ix]] = _dict\n",
    "        \n",
    "        for im in images_to_move:\n",
    "            stripped_im = im[im.index('/')+1:]\n",
    "            shutil.move(src=conf['TEST_IMG_DIR']+im, \n",
    "                        dst=conf['CACHE_DIR']+'/'+stripped_im)\n",
    "            \n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_1 = get_predictions(tag='NV_NON_NV', verbose=1)\n",
    "with open(conf['PICKLE_FILES']['NV_NON_NV'], 'wb') as handle:\n",
    "    pickle.dump(preds_1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('Pickled NV_NON_NV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# \\*Please restart kernel here\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2 = get_predictions(tag='DF_VASC_OTHERS', verbose=1)\n",
    "with open(conf['PICKLE_FILES']['DF_VASC_OTHERS'], 'wb') as handle:\n",
    "    pickle.dump(preds_2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('Pickled DF_VASC_OTHERS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# \\*Please restart kernel here\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_3 = get_predictions(tag='BCC_OTHERS', verbose=1)\n",
    "with open(conf['PICKLE_FILES']['BCC_OTHERS'], 'wb') as handle:\n",
    "    pickle.dump(preds_3, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('Pickled BCC_OTHERS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\*Please restart kernel here\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_4 = get_predictions(tag='AKIEC_OTHERS', verbose=1)\n",
    "with open(conf['PICKLE_FILES']['AKIEC_OTHERS'], 'wb') as handle:\n",
    "    pickle.dump(preds_4, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('Pickled AKIEC_OTHERS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\*Please restart kernel here\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_5 = get_predictions(tag='MEL_BKL', verbose=1)\n",
    "with open(conf['PICKLE_FILES']['MEL_BKL'], 'wb') as handle:\n",
    "    pickle.dump(preds_5, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('Pickled MEL_BKL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\*Please restart kernel here\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Get all the predictions.\n",
    "with open(conf['PICKLE_FILES']['NV_NON_NV'], 'rb') as handle:\n",
    "    preds_1 = pickle.load(handle)\n",
    "print(len(preds_1['NV']))    \n",
    "with open(conf['PICKLE_FILES']['DF_VASC_OTHERS'], 'rb') as handle:\n",
    "    preds_2 = pickle.load(handle)\n",
    "    \n",
    "with open(conf['PICKLE_FILES']['BCC_OTHERS'], 'rb') as handle:\n",
    "    preds_3 = pickle.load(handle)\n",
    "\n",
    "with open(conf['PICKLE_FILES']['AKIEC_OTHERS'], 'rb') as handle:\n",
    "    preds_4 = pickle.load(handle)\n",
    "    \n",
    "with open(conf['PICKLE_FILES']['MEL_BKL'], 'rb') as handle:\n",
    "    preds_5 = pickle.load(handle)\n",
    "\n",
    "\n",
    "\n",
    "class_list = conf['CLASSES']\n",
    "prediction_matrix = np.zeros((1512, len(class_list)))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "# df_columns = ['image'] + class_list\n",
    "# df.columns = df_columns\n",
    "ix_to_column = {col: i for i, col in enumerate(class_list)}\n",
    "\n",
    "idx = 0\n",
    "filenames = []\n",
    "for img, probab in preds_1['NV'].items():\n",
    "    prediction_matrix[idx, ix_to_column['NV']] = probab\n",
    "    filenames.append(img)\n",
    "    idx += 1\n",
    "\n",
    "for img in preds_2['DF'].keys():\n",
    "    probab_df = preds_2['DF'][img]\n",
    "    probab_vasc = preds_2['VASC'][img]\n",
    "    prediction_matrix[idx, ix_to_column['DF']] = probab_df\n",
    "    prediction_matrix[idx, ix_to_column['VASC']] = probab_vasc\n",
    "    filenames.append(img)\n",
    "    idx += 1\n",
    "    \n",
    "for img, probab in preds_3['BCC'].items():\n",
    "    prediction_matrix[idx, ix_to_column['BCC']] = probab\n",
    "    filenames.append(img)\n",
    "    idx += 1\n",
    "    \n",
    "for img, probab in preds_4['AKIEC'].items():\n",
    "    prediction_matrix[idx, ix_to_column['AKIEC']] = probab\n",
    "    filenames.append(img)\n",
    "    idx += 1\n",
    "\n",
    "# print(preds_5)\n",
    "# for img in preds_5['MEL'].keys():\n",
    "#     probab_mel = preds_5['MEL'][img]\n",
    "#     probab_bkl = preds_5['BKL'][img]\n",
    "#     prediction_matrix[idx, ix_to_column['MEL']] = probab_mel\n",
    "#     prediction_matrix[idx, ix_to_column['BKL']] = probab_bkl\n",
    "#     filenames.append(img)\n",
    "#     idx += 1\n",
    "\n",
    "for img, probab in preds_5['MEL'].items():\n",
    "    prediction_matrix[idx, ix_to_column['MEL']] = probab\n",
    "    filenames.append(img)\n",
    "    idx += 1\n",
    "\n",
    "for img, probab in preds_5['BKL'].items():\n",
    "    prediction_matrix[idx, ix_to_column['BKL']] = probab\n",
    "    filenames.append(img)\n",
    "    idx += 1\n",
    "\n",
    "print(idx)\n",
    "df['image'] = filenames\n",
    "for class_name, ix in ix_to_column.items():\n",
    "    df[class_name] = prediction_matrix[:, ix]\n",
    "    \n",
    "df = df.sort_values('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    if '/' in x:\n",
    "        x = x[x.index('/')+1:].strip('.jpg')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image'] = df['image'].map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('image')\n",
    "df.to_csv('test_predictions_hierarchical.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
