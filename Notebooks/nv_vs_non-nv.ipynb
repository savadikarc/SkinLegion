{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original width: 600\n",
    "# IM_WIDTH = 400 # Keep width = 400 for InceptionV4\n",
    "# IM_WIDTH = 300 # Keep width = 300 for ResNet50\n",
    "IM_WIDTH = 224 # Keep width = 224 for InceptionV3\n",
    "\n",
    "# Original height: 450\n",
    "# IM_HEIGHT = 300 # Keep height = 300 for InceptionV4\n",
    "# IM_HEIGHT = 225 # Keep height = 225 for ResNet50\n",
    "IM_HEIGHT = 168 # Keep height = 168 for InceptionV3\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "global_mean = np.load('/home/ubuntu/Data/Skin/nv_non_nv/mean_image_nv_non_nv.npz')['image'].astype(np.uint8)\n",
    "mean_image = Image.fromarray(global_mean).resize((IM_WIDTH, IM_HEIGHT))\n",
    "global_mean = np.asarray(mean_image, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    return image - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "train_img = ImageDataGenerator(preprocessing_function=preprocess_image, rescale=1./255)\n",
    "\n",
    "img_gen = ImageDataGenerator(preprocessing_function=preprocess_image, rescale=1./255)\n",
    "\n",
    "train_gen = train_img.flow_from_directory('/home/ubuntu/Data/Skin/nv_non_nv/train', \n",
    "                                        target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                        class_mode='binary', \n",
    "                                        shuffle=True, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        classes=['NON_NV', 'NV']\n",
    "                                       )\n",
    "print('Training Set Generator done.\\n')\n",
    "val_gen = img_gen.flow_from_directory('/home/ubuntu/Data/Skin/nv_non_nv/val', \n",
    "                                        target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                        class_mode='binary', \n",
    "                                        shuffle=True, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        classes=['NON_NV', 'NV']\n",
    "                                     )\n",
    "print('Validation Set Generator done.\\n')\n",
    "test_gen = img_gen.flow_from_directory('/home/ubuntu/Data/Skin/nv_non_nv/test', \n",
    "                                        target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                        class_mode='binary', \n",
    "                                        shuffle=False, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        classes=['NON_NV', 'NV']\n",
    "                                      )\n",
    "print('Test Set Generator done.\\n')\n",
    "y_train = train_gen.classes\n",
    "weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {i: weights[i] for i in range(len(weights))}\n",
    "\n",
    "print(class_weights)\n",
    "print(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_units = 1024\n",
    "model_name = 'inceptionv3'\n",
    "# model_name = 'resnet50'\n",
    "# model_name = 'inceptionv4'\n",
    "# model_name = 'vgg16'\n",
    "# model_name = 'densenet'\n",
    "training_set = 'full_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "import sys\n",
    "sys.path.append('/home/ubuntu/Notebooks/Models/')\n",
    "# import inception_v4\n",
    "from keras import Model\n",
    "from keras.layers import (Dense, Activation, Dropout, \n",
    "                          BatchNormalization, Flatten, GlobalAveragePooling2D)\n",
    "\n",
    "inc = InceptionV3(include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3), weights='imagenet')\n",
    "# inc = ResNet50(include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3), weights='imagenet')\n",
    "# inc = VGG16(include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3), weights='imagenet')\n",
    "# inc = inception_v4.create_model(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "# inc.load_weights('/home/ubuntu/Notebooks/Models/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "x = inc.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_hidden_units)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inc.input, outputs=out)\n",
    "\n",
    "for layer in inc.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "decision_weights = model.layers[-1].get_weights()\n",
    "print(decision_weights[0].shape, decision_weights[1].shape)\n",
    "decision_weights[1] -= 0.7\n",
    "model.layers[-1].set_weights(decision_weights)\n",
    "print(model.layers[-1].get_weights()[1])\n",
    "filename = 'final_nv_non_nv_' + model_name + '_' + str(num_hidden_units) + '_' + training_set + '.h5'\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0., 1.)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0., 1.)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return ( 2*(precision * recall) / (precision + recall + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0., 1.)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0., 1.)))\n",
    "    return (true_positives / (predicted_positives + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0., 1.)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0., 1.)))\n",
    "    return (true_positives / (possible_positives + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "# model.compile(loss='hinge', optimizer=Adam(1e-5), metrics=[svm_binary_accuracy])\n",
    "\n",
    "_ = model.fit_generator(train_gen, \n",
    "                        steps_per_epoch=train_gen.samples//BATCH_SIZE + 1, \n",
    "                        validation_data=val_gen, \n",
    "                        validation_steps=val_gen.samples//BATCH_SIZE + 1, \n",
    "                        shuffle=True, \n",
    "                        epochs=1,\n",
    "                        class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_batchnorm(final_model):\n",
    "    for i, layer in enumerate(final_model.layers):\n",
    "        if type(layer) is BatchNormalization:\n",
    "            input_shape = layer.input_shape\n",
    "            gamma = np.ones((input_shape[-1],))\n",
    "            beta = np.zeros((input_shape[-1],))\n",
    "            moving_mean = np.zeros((input_shape[-1],))\n",
    "            moving_variance = np.ones((input_shape[-1],))\n",
    "            config = layer.get_config()\n",
    "            if config['scale'] and config['center']:\n",
    "                layer.set_weights([gamma, beta, moving_mean, moving_variance])\n",
    "            elif config['scale'] and not config['center']:\n",
    "                layer.set_weights([gamma, moving_mean, moving_variance])\n",
    "            elif not config['scale'] and config['center']:\n",
    "                layer.set_weights([beta, moving_mean, moving_variance])\n",
    "#             print('Weights Changed')\n",
    "        \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# model = reset_batchnorm(model)\n",
    "# print('All BatchNorm layers were reset')\n",
    "\n",
    "optimizer = Adam(lr=1e-4, decay=5e-4)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, \n",
    "              metrics=['accuracy', precision, recall, f1])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4, decay=5e-2), metrics=['accuracy', precision, recall, f1])\n",
    "\n",
    "print('Model compiled')\n",
    "initial_epoch=0\n",
    "num_epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompiling model AFTER running for x epochs.\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-7, decay=1e-3), metrics=['accuracy', precision, recall, f1])\n",
    "print('Model re-compiled')\n",
    "initial_epoch=13\n",
    "\n",
    "filename = filename[:-3] + '_2.h5'\n",
    "print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# reducer = step_decay_schedule(initial_lr=1e-5, step_size=train_gen.samples//BATCH_SIZE)\n",
    "\n",
    "# plateau_watcher = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filename, \n",
    "                             save_best_only=True, \n",
    "                             mode='max',\n",
    "                             monitor='val_f1', \n",
    "                             verbose=1)\n",
    "\n",
    "stopper = EarlyStopping(monitor='val_loss', mode='min', patience=4)\n",
    "\n",
    "h = model.fit_generator(train_gen, \n",
    "                        steps_per_epoch=train_gen.samples//BATCH_SIZE + 1, \n",
    "                        validation_data=val_gen, \n",
    "                        validation_steps=val_gen.samples//BATCH_SIZE + 1, \n",
    "                        shuffle=True, \n",
    "                        epochs=num_epochs, \n",
    "                        class_weight=class_weights, \n",
    "                        callbacks=[checkpoint, stopper])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(h.history['loss'], 'r-')\n",
    "plt.plot(h.history['val_loss'], 'b-')\n",
    "plt.title('Loss plot')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(h.history['f1'], 'r-')\n",
    "plt.plot(h.history['val_f1'], 'b-')\n",
    "plt.title('Loss plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "m = load_model(filename, compile=True, custom_objects={'f1':f1, 'precision':precision, 'recall':recall})\n",
    "print('Best model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_gen = img_gen.flow_from_directory('/home/ubuntu/Data/Skin/nv_non_nv/test', \n",
    "                                        target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                        class_mode='binary', \n",
    "                                        shuffle=False, \n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                      )\n",
    "\n",
    "y_pred = model.predict_generator(pre_gen, steps=pre_gen.samples//BATCH_SIZE + 1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_gen.classes\n",
    "\n",
    "y_pred[y_pred >= 0.5] = 1\n",
    "y_pred[y_pred < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_true=y_true.ravel(), y_pred=y_pred.ravel()))\n",
    "\n",
    "print(classification_report(y_true=y_true.ravel(), y_pred=y_pred.ravel()))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_true, y_pred)\n",
    "model_auc = auc(fpr, tpr)\n",
    "\n",
    "print('AUC: {}'.format(model_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
