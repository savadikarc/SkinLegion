{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original width: 600\n",
    "# IM_WIDTH = 400 # Keep width = 400 for InceptionV4\n",
    "IM_WIDTH = 300 # Keep width = 300 for ResNet50\n",
    "\n",
    "# Original height: 450\n",
    "# IM_HEIGHT = 300 # Keep height = 300 for InceptionV4\n",
    "IM_HEIGHT = 225 # Keep height = 225 for ResNet50\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "SEED = 429347\n",
    "\n",
    "data_path = '/home/ubuntu/Data/Skin/df_vasc_others/'\n",
    "\n",
    "global_mean = np.load(data_path + 'mean_image_df_vasc_others.npz')['image'].astype(np.uint8)\n",
    "mean_image = Image.fromarray(global_mean).resize((IM_WIDTH, IM_HEIGHT))\n",
    "global_mean = np.asarray(mean_image, dtype=np.float32)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    return image - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "train_img = ImageDataGenerator(preprocessing_function=preprocess_image, rescale=1./255)\n",
    "\n",
    "img_gen = ImageDataGenerator(preprocessing_function=preprocess_image, rescale=1./255)\n",
    "\n",
    "train_gen = train_img.flow_from_directory(data_path + 'train', \n",
    "                                        target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                        class_mode='categorical', \n",
    "                                        shuffle=True, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        classes=['DF', 'VASC', 'OTHERS'], \n",
    "                                          seed=SEED\n",
    "                                       )\n",
    "\n",
    "print('Training Set Generator done.\\n')\n",
    "val_gen = img_gen.flow_from_directory(data_path + 'val', \n",
    "                                      target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                      class_mode='categorical', \n",
    "                                      shuffle=True, \n",
    "                                      batch_size=BATCH_SIZE, \n",
    "                                      classes=['DF', 'VASC', 'OTHERS'],\n",
    "                                      seed=SEED\n",
    "                                     )\n",
    "\n",
    "print('Validation Set Generator done.\\n')\n",
    "test_gen = img_gen.flow_from_directory(data_path + 'test', \n",
    "                                       target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                       class_mode='categorical', \n",
    "                                       shuffle=False, \n",
    "                                       batch_size=BATCH_SIZE, \n",
    "                                       classes=['DF', 'VASC', 'OTHERS'],\n",
    "                                       seed=SEED\n",
    "                                      )\n",
    "print('Test Set Generator done.\\n')\n",
    "y_train = train_gen.classes\n",
    "weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {i: weights[i] for i in range(len(weights))}\n",
    "\n",
    "print(class_weights)\n",
    "print(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_units = 512\n",
    "model_name = 'inceptionv3'\n",
    "# model_name = 'resnet50'\n",
    "# model_name = 'inceptionv4'\n",
    "# model_name = 'vgg16'\n",
    "# model_name = 'densenet'\n",
    "\n",
    "train_type = 'full_train'\n",
    "data = 'df_vasc_others'\n",
    "\n",
    "filename = data + '_' + model_name + '_' + str(num_hidden_units) + '_' + train_type + '.h5'\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# import inception_v4\n",
    "from keras import Model\n",
    "from keras.layers import (Dense, Activation, Dropout, \n",
    "                          BatchNormalization, Flatten, GlobalAveragePooling2D)\n",
    "\n",
    "inc = InceptionV3(include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3), weights='imagenet')\n",
    "# inc = ResNet50(include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3), weights='imagenet')\n",
    "# inc = VGG16(include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3), weights='imagenet')\n",
    "# inc = inception_v4.create_model(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3))\n",
    "# inc.load_weights('/home/ubuntu/Notebooks/Models/inception-v4_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "x = inc.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_hidden_units)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "out = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inc.input, outputs=out)\n",
    "\n",
    "# last_layer_weights = model.layers[-1].get_weights()\n",
    "# last_layer_weights[1][:2] += 1.\n",
    "# last_layer_weights[1][2:] -= 1.\n",
    "\n",
    "# model.layers[-1].set_weights(last_layer_weights)\n",
    "\n",
    "# print(model.layers[-1].get_weights()[1])\n",
    "\n",
    "for layer in inc.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return ( 2*(precision * recall) / (precision + recall + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return (true_positives / (predicted_positives + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return (true_positives / (possible_positives + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(5e-4))\n",
    "\n",
    "_ = model.fit_generator(train_gen, \n",
    "                        steps_per_epoch=train_gen.samples//BATCH_SIZE + 1, \n",
    "                        validation_data=val_gen, \n",
    "                        validation_steps=val_gen.samples//BATCH_SIZE + 1, \n",
    "                        shuffle=True, \n",
    "                        epochs=1, \n",
    "                        class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4, decay=0.0005), metrics=['accuracy', precision, recall, f1])\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(lr=1e-4, decay=5e-4), \n",
    "              metrics=['categorical_accuracy', precision, recall, f1])\n",
    "print('Model compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompiling model AFTER running for x epochs.\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=5e-6, decay=5e-4), metrics=['accuracy', precision, recall, f1])\n",
    "print('Model re-compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(filename, \n",
    "                             save_best_only=True, mode='max',\n",
    "                             monitor='val_f1', verbose=1)\n",
    "reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.05, mode='min', patience=2, verbose=1)\n",
    "stopper = EarlyStopping(monitor='val_loss', mode='min', patience=3, verbose=1)\n",
    "\n",
    "h = model.fit_generator(train_gen, \n",
    "                        steps_per_epoch=train_gen.samples//BATCH_SIZE + 1, \n",
    "                        validation_data=val_gen, \n",
    "                        validation_steps=val_gen.samples//BATCH_SIZE + 1, \n",
    "                        shuffle=True, \n",
    "                        epochs=10,\n",
    "                        class_weight=class_weights, \n",
    "                        callbacks=[checkpoint, stopper, reducer])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(h.history['loss'], 'r-')\n",
    "plt.plot(h.history['val_loss'], 'b-')\n",
    "plt.title('Loss plot')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(h.history['f1'], 'r-')\n",
    "plt.plot(h.history['val_f1'], 'b-')\n",
    "plt.title('F1 plot')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(h.history['precision'], 'r-')\n",
    "plt.plot(h.history['val_precision'], 'b-')\n",
    "plt.title('Precision plot')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(h.history['recall'], 'r-')\n",
    "plt.plot(h.history['val_recall'], 'b-')\n",
    "plt.title('Recall plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "m = load_model('df_vasc_others_inceptionv3_512_full_train.h5', \n",
    "               compile=True, \n",
    "               custom_objects={'f1':f1, \n",
    "                               'precision':precision, \n",
    "                               'recall':recall})\n",
    "print('Best model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict_generator(test_gen, verbose=1)\n",
    "y_pred = m.predict_generator(test_gen, verbose=1)\n",
    "# y_pred = model.predict_generator(pre_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_gen.classes\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_true=y_true.ravel(), y_pred=y_pred.ravel()))\n",
    "\n",
    "print(classification_report(y_true=y_true.ravel(), y_pred=y_pred.ravel()))\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_true, y_pred)\n",
    "model_auc = auc(fpr, tpr)\n",
    "\n",
    "print('AUC: {}'.format(model_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_saliency, overlay\n",
    "from vis.utils import utils\n",
    "from keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = '/home/ubuntu/Data/Skin/nv_non_nv/toy_train/'\n",
    "path_to_models = '/home/ubuntu/Notebooks/Rahul/Models/Hierarchical/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_nv = os.listdir(path_to_images + 'NV')\n",
    "images_non_nv = os.listdir(path_to_images + 'NON_NV')\n",
    "\n",
    "model_name = 'nv_non_nv_inception_holdout_test_hist.h5' # Model here\n",
    "layer_idx = -1 # Last prediction layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[layer_idx].activation = activations.linear\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.layers[-1].get_config())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
