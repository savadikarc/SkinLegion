{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the temporary directories.\n",
    "if not os.path.exists('temp_folder'):\n",
    "    os.makedirs('temp_folder')\n",
    "\n",
    "if not os.path.exists('temp_folder/non_nv/'):\n",
    "    os.makedirs('temp_folder/non_nv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SEED = 10\n",
    "\n",
    "IM_HEIGHT_NV = 168\n",
    "IM_WIDTH_NV = 224\n",
    "\n",
    "IM_HEIGHT_REST = 225\n",
    "IM_WIDTH_REST = 300\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "global_mean_nv = np.load('../../Data/Skin/nv_non_nv/mean_image_nv_non_nv.npz')['image'].astype(np.uint8)\n",
    "nv_mean_image = (Image.fromarray(global_mean_nv)).resize((IM_WIDTH_NV, IM_HEIGHT_NV))\n",
    "global_mean_nv = np.asarray(nv_mean_image).astype(np.float32)\n",
    "\n",
    "global_mean_rest = np.load('../../Data/Skin/six_way_level_two/mean_image_six_way_level_two.npz')['image'].astype(np.uint8)\n",
    "rest_mean_image = (Image.fromarray(global_mean_rest)).resize((IM_WIDTH_REST, IM_HEIGHT_REST))\n",
    "global_mean_rest = np.asarray(rest_mean_image).astype(np.float32)\n",
    "\n",
    "\n",
    "model_name_nv = 'nv_non_nv_inceptionv3_512_custom_weight_init_full_train-ve1.h5'\n",
    "model_path_nv = '/home/ubuntu/Notebooks/Rahul/Hierarchical/Finalized Hierarchical Models/' + model_name_nv\n",
    "\n",
    "model_name_rest = 'six_way_level_two_inceptionv3_256_full_train_gauss_noise.h5'\n",
    "model_path_rest = '/home/ubuntu/Notebooks/Bhushan/' + model_name_rest\n",
    "\n",
    "print(global_mean_nv.shape)\n",
    "print(global_mean_rest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_nv_image(image):\n",
    "    return (image - global_mean_nv)\n",
    "\n",
    "def preprocess_rest_image(image):\n",
    "    return (image - global_mean_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return ( 2*(precision * recall) / (precision + recall + K.epsilon()) )\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return (true_positives / (predicted_positives + K.epsilon()))\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return (true_positives / (possible_positives + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import compute_class_weight\n",
    "from PIL import Image\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen_nv = ImageDataGenerator(preprocessing_function=preprocess_nv_image, rescale=1./255.)\n",
    "# img_gen_rest = ImageDataGenerator(preprocessing_function=preprocess_rest_image, rescale=1./255.)\n",
    "\n",
    "val_gen_nv = img_gen_nv.flow_from_directory('/home/ubuntu/Data/Skin/Test/', \n",
    "                                        target_size=(IM_HEIGHT_NV, IM_WIDTH_NV), \n",
    "                                        class_mode=None, \n",
    "                                        shuffle=False, \n",
    "                                        batch_size=BATCH_SIZE)\n",
    "\n",
    "# Load NV - Non-NV model\n",
    "level_one_model = load_model(model_path_nv, compile=True, custom_objects={'f1': f1,\n",
    "                                                                          'precision': precision,\n",
    "                                                                          'recall': recall})\n",
    "\n",
    "level_one_preds = level_one_model.predict_generator(val_gen_nv,\n",
    "                                                    verbose=1)\n",
    "print(level_one_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NV-Non_NV\n",
    "val_files = val_gen_nv.filenames\n",
    "\n",
    "nv_indices = np.where(level_one_preds > 0.5)[0]\n",
    "non_nv_indices = np.where(level_one_preds <= 0.5)[0]\n",
    "\n",
    "nv_preds = level_one_preds[level_one_preds > 0.5]\n",
    "non_nv_preds = level_one_preds[level_one_preds <= 0.5]\n",
    "\n",
    "nv_files = [val_files[x] for x in nv_indices]\n",
    "non_nv_files = [val_files[x] for x in non_nv_indices]\n",
    "\n",
    "nv_dict = dict({nv_files[i]: nv_preds[i] for i in range(len(nv_files))})\n",
    "\n",
    "with open('nv_predictions_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(nv_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "print('Dumped NV records\\nImages identified as NV: {}'.format(len(nv_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the non-nv files.\n",
    "for non_nv_file in non_nv_files:\n",
    "    shutil.copy(src='/home/ubuntu/Data/Skin/Test/' + non_nv_file,\n",
    "               dst='temp_folder/non_nv/' + non_nv_file[4:])\n",
    "\n",
    "print('Done copying to temporary folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done with NV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_gen_nv = ImageDataGenerator(preprocessing_function=preprocess_nv_image, rescale=1./255.)\n",
    "img_gen_rest = ImageDataGenerator(preprocessing_function=preprocess_rest_image, rescale=1./255.)\n",
    "\n",
    "val_gen_rest = img_gen_rest.flow_from_directory('temp_folder/', \n",
    "                                        target_size=(IM_HEIGHT_REST, IM_WIDTH_REST), \n",
    "                                        class_mode=None, \n",
    "                                        shuffle=False, \n",
    "                                        batch_size=BATCH_SIZE)\n",
    "\n",
    "# Load 6 way model model\n",
    "level_two_model = load_model(model_path_rest, compile=True, custom_objects={'f1': f1,\n",
    "                                                                          'precision': precision,\n",
    "                                                                          'recall': recall})\n",
    "\n",
    "level_two_preds = level_two_model.predict_generator(val_gen_rest, verbose=1)\n",
    "print(level_two_preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_files = val_gen_rest.filenames\n",
    "\n",
    "predictions = np.zeros((1512, 7))\n",
    "\n",
    "with open('nv_predictions_test.pickle', 'rb') as handle:\n",
    "    nv_predictions = pickle.load(handle)\n",
    "# print(nv_predictions)\n",
    "filenames = []\n",
    "idx = 0\n",
    "\n",
    "for filename in nv_predictions.keys():\n",
    "    img_name = filename[filename.index('/') + 1:]\n",
    "    filenames.append(img_name)\n",
    "    predictions[idx, 1] = nv_predictions[filename]\n",
    "    idx += 1\n",
    "\n",
    "n_nv = idx\n",
    "for file in rest_files:\n",
    "    filename = file[7:]\n",
    "    filenames.append(filename)\n",
    "    predictions[idx, 0] = level_two_preds[idx - n_nv, 0]\n",
    "    predictions[idx, 1] = 0\n",
    "    predictions[idx, 2:] = level_two_preds[idx - n_nv, 1:]\n",
    "    idx += 1\n",
    "    \n",
    "print(idx)\n",
    "np.savez_compressed('pred_test.npz', pred = predictions)\n",
    "print('Saved MoFo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv_frame = pd.DataFrame()\n",
    "# map_indices_rev = {val: key for key, val in map_indices.items()}\n",
    "csv_frame['image'] = [filename.strip('.jpg') for filename in filenames]\n",
    "class_list = ['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']\n",
    "for idx in range(7):\n",
    "    csv_frame[class_list[idx]] = predictions[:, idx]\n",
    "    \n",
    "csv_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_frame = csv_frame.sort_values('image')\n",
    "csv_frame.to_csv('test_sixway_predictions.csv', index=False)\n",
    "# csv_frame.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
