{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Original width: 600\n",
    "IM_WIDTH = 300 #224\n",
    "\n",
    "# Original height: 450\n",
    "IM_HEIGHT = 225 #168\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Random seed.\n",
    "SEED = 74638\n",
    "\n",
    "data_path = '/home/ubuntu/Data/Skin/mel_bkl/'\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "global_mean = np.load(data_path + 'mean_image_mel_bkl.npz')['image']\n",
    "resnet_im = (Image.fromarray(global_mean.astype(np.uint8))).resize((IM_WIDTH, IM_HEIGHT))\n",
    "\n",
    "global_mean = np.asarray(resnet_im)\n",
    "print(global_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    return (image - global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "train_img = ImageDataGenerator(preprocessing_function=preprocess_image, rescale=1./255)\n",
    "\n",
    "img_gen = ImageDataGenerator(preprocessing_function=preprocess_image, rescale=1./255)\n",
    "\n",
    "train_gen = train_img.flow_from_directory(data_path + 'train', \n",
    "                                        target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                        class_mode='binary', \n",
    "                                        shuffle=True, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        classes=['BKL', 'MEL']\n",
    "                                       )\n",
    "print('Training Set Generator done.\\n')\n",
    "val_gen = img_gen.flow_from_directory(data_path + 'val', \n",
    "                                        target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                        class_mode='binary', \n",
    "                                        shuffle=True, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                        classes=['BKL', 'MEL']\n",
    "                                     )\n",
    "print('Validation Set Generator done.\\n')\n",
    "test_gen = img_gen.flow_from_directory(data_path + 'test', \n",
    "                                        target_size=(IM_HEIGHT, IM_WIDTH), \n",
    "                                        class_mode='binary', \n",
    "                                        shuffle=False, \n",
    "                                        batch_size=BATCH_SIZE, \n",
    "                                      )\n",
    "print('Test Set Generator done.\\n')\n",
    "y_train = train_gen.classes\n",
    "weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weights = {i: weights[i] for i in range(len(weights))}\n",
    "\n",
    "print(class_weights)\n",
    "print(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'inceptionv3'\n",
    "# model_name = 'resnet50'\n",
    "num_hidden_units = 512\n",
    "training_set = 'full_train'\n",
    "filename = 'final_bkl_mel_' + model_name + '_' + str(num_hidden_units) + '_'+ training_set + '_1.h5'\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return ( 2*(precision * recall) / (precision + recall + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    return (true_positives / (predicted_positives + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return (true_positives / (possible_positives + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "from keras import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Activation, Dropout, Flatten, BatchNormalization\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import keras.regularizers\n",
    "\n",
    "inc = InceptionV3(include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH, 3), weights='imagenet')\n",
    "\n",
    "x = inc.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(num_hidden_units)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "out = Dense(1, activation='sigmoid', name='new_output')(x)\n",
    "model = Model(inc.input, out)\n",
    "\n",
    "'''\n",
    "Best recorded metrics:\n",
    "                                 precision    recall  f1-score   support\n",
    "\n",
    "        BKL       0.90      0.90      0.90       110\n",
    "        MEL       0.90      0.90      0.90       112\n",
    "\n",
    "avg / total       0.90      0.90      0.90       222\n",
    "\n",
    "[[ 99  11]\n",
    " [ 11 101]]\n",
    " \n",
    "AUC score: N/A\n",
    "\n",
    "'''\n",
    "\n",
    "last_layer_weights = model.layers[-1].get_weights()\n",
    "last_layer_weights[1][0] -= 0.2\n",
    "\n",
    "model.layers[-1].set_weights(last_layer_weights)\n",
    "\n",
    "print(model.layers[-1].get_weights()[1])\n",
    "\n",
    "for layer in inc.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(0.0001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "_ = model.fit_generator(train_gen, \n",
    "                        steps_per_epoch=train_gen.samples//BATCH_SIZE + 1, \n",
    "                        validation_data=val_gen, \n",
    "                        validation_steps=val_gen.samples//BATCH_SIZE + 1, \n",
    "                        shuffle=True, \n",
    "                        epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[-1].get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "for l in model.layers:\n",
    "    l.trainable = True\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "                      optimizer=Adam(lr=5e-5, decay=5e-4), \n",
    "                      metrics=['accuracy', precision, recall, f1])\n",
    "\n",
    "print('Model compiled')\n",
    "\n",
    "initial_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompiling model AFTER running for x epochs.\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-5, decay=5e-2), metrics=['categorical_accuracy', precision, recall, f1])\n",
    "print('Model re-compiled')\n",
    "\n",
    "print(filename)\n",
    "\n",
    "initial_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Model checkpointing.\n",
    "checkpoint = ModelCheckpoint(filename, \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_f1', \n",
    "                             verbose=1, mode='max')\n",
    "\n",
    "# Preventing unnecessary training.\n",
    "stopper = EarlyStopping(monitor='val_loss', mode='min', patience=3)\n",
    "\n",
    "h = model.fit_generator(train_gen, \n",
    "                                steps_per_epoch=train_gen.samples//BATCH_SIZE + 1, \n",
    "                                validation_data=val_gen, \n",
    "                                validation_steps=val_gen.samples//BATCH_SIZE + 1, \n",
    "                                shuffle=True, \n",
    "                                epochs=12,\n",
    "                                initial_epoch=0,\n",
    "                                callbacks=[checkpoint, stopper], \n",
    "                                class_weight=class_weights)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(h.history['loss'], 'r-')\n",
    "plt.plot(h.history['val_loss'], 'b-')\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(h.history['f1'], 'r-')\n",
    "plt.plot(h.history['val_f1'], 'b-')\n",
    "plt.title('F1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_gen.classes\n",
    "\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred[y_pred >= 0.5] = 1\n",
    "y_pred[y_pred < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_true=y_true.ravel(), \n",
    "                            y_pred=y_pred.ravel(),\n",
    "                            target_names=['BKL', 'MEL']))\n",
    "print(confusion_matrix(y_true=y_true.ravel(), y_pred=y_pred.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "        BKL       0.90      0.90      0.90       110\n",
    "        MEL       0.90      0.90      0.90       112\n",
    "\n",
    "avg / total       0.90      0.90      0.90       222\n",
    "\n",
    "[[ 99  11]\n",
    " [ 11 101]]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
